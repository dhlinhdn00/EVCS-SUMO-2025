{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bced016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import sumolib\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/src') \n",
    "from config import *\n",
    "\n",
    "def get_invalid_routes_summary(dir_path):\n",
    "    \"\"\"\n",
    "    Extract invalid-route vehicle IDs from\n",
    "    <dir_path>/log/duarouter.log and then parse\n",
    "    <dir_path>/trips.xml to get fromTaz and toTaz.\n",
    "    Returns two DataFrames:\n",
    "      - detailed_df: columns [vehicle_id, fromTaz, toTaz]\n",
    "      - summary_df: columns [fromTaz, toTaz, error_count]\n",
    "    \"\"\"\n",
    "    # Build fixed paths\n",
    "    log_path = os.path.join(dir_path, 'logs', 'duarouter.log')\n",
    "    trips_path = os.path.join(dir_path, 'trips.xml')\n",
    "\n",
    "    # 1. Read log to collect invalid vehicle IDs\n",
    "    invalid_ids = set()\n",
    "    pattern = re.compile(r\"Warning: The vehicle '(.+?)' has no valid route\")\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            m = pattern.search(line)\n",
    "            if m:\n",
    "                invalid_ids.add(m.group(1))\n",
    "\n",
    "    # 2. Parse trips.xml and gather details\n",
    "    tree = ET.parse(trips_path)\n",
    "    root = tree.getroot()\n",
    "    details = []\n",
    "    for trip in root.findall('trip'):\n",
    "        vid = trip.get('id')\n",
    "        if vid in invalid_ids:\n",
    "            details.append({\n",
    "                'vehicle_id': vid,\n",
    "                'fromTaz':    trip.get('fromTaz'),\n",
    "                'toTaz':      trip.get('toTaz')\n",
    "            })\n",
    "\n",
    "    detailed_df = pd.DataFrame(details, columns=['vehicle_id', 'fromTaz', 'toTaz'])\n",
    "\n",
    "    # 3. Summarize counts by fromTaz → toTaz\n",
    "    summary_df = (\n",
    "        detailed_df\n",
    "        .groupby(['fromTaz', 'toTaz'], as_index=False)\n",
    "        .size()\n",
    "        .rename(columns={'size': 'error_count'})\n",
    "    )\n",
    "\n",
    "    return detailed_df, summary_df\n",
    "\n",
    "# base_dir = \"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/result/experiments/20-05-25-checknewmap\"\n",
    "# detailed_df, summary_df = get_invalid_routes_summary(base_dir)\n",
    "\n",
    "# print(f\"Total invalid routes: {len(detailed_df)}\\n\")\n",
    "# display(detailed_df)\n",
    "\n",
    "# print(\"\\nError counts by fromTaz -> toTaz:\")\n",
    "# display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e2e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "import importlib.util\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "def extract_failed_trips(log_path):\n",
    "    \"\"\"Return set of vehicle IDs that duarouter flagged as 'no valid route'.\"\"\"\n",
    "    pat = re.compile(r\"Warning: The vehicle '(.+?)' has no valid route\")\n",
    "    failed = set()\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            m = pat.search(line)\n",
    "            if m:\n",
    "                failed.add(m.group(1))\n",
    "    return failed\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "def parse_taz_file(taz_path):\n",
    "    \"\"\"\n",
    "    Parse the TAZ XML that looks like:\n",
    "      <tazs>\n",
    "        <taz id=\"2\" ...>\n",
    "          <tazSource id=\"edgeA\"/>\n",
    "          <tazSink   id=\"edgeB\"/>\n",
    "          ...\n",
    "        </taz>\n",
    "      </tazs>\n",
    "    Returns dict: { zone_id: [edgeID, edgeID, …], … }\n",
    "    \"\"\"\n",
    "    tree = ET.parse(taz_path)\n",
    "    root = tree.getroot()\n",
    "    taz_map = {}\n",
    "    for taz in root.findall('taz'):\n",
    "        zid = taz.get('id')\n",
    "        edge_ids = []\n",
    "        for child in taz:\n",
    "            if child.tag in ('tazSource', 'tazSink'):\n",
    "                edge_ids.append(child.get('id'))\n",
    "        taz_map[zid] = edge_ids\n",
    "    return taz_map\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "def call_findAllRoutes_inprocess(script_path, net_file, src_edges, tgt_edges, out_file):\n",
    "    \"\"\"\n",
    "    Load findAllRoutes.py as a module and call its main() with Python args.\n",
    "    This avoids shell argument-length limits.\n",
    "    \"\"\"\n",
    "    # 1) Dynamically load the module\n",
    "    spec = importlib.util.spec_from_file_location(\"findAllRoutes\", script_path)\n",
    "    far = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(far)\n",
    "\n",
    "    # 2) Build a fake argv list\n",
    "    args = [\n",
    "        \"--net-file\",    net_file,\n",
    "        \"--source-edges\", \",\".join(src_edges),\n",
    "        \"--target-edges\", \",\".join(tgt_edges),\n",
    "        \"--output-file\",  out_file\n",
    "    ]\n",
    "\n",
    "    # 3) Parse options & invoke\n",
    "    options = far.get_options(args)\n",
    "    far.main(options)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "def repair_trips(\n",
    "    base_dir,\n",
    "    net_file,\n",
    "    taz_file,\n",
    "    findall_script,\n",
    "    out_routes_dir=\"fixed_routes\",\n",
    "    out_trips=\"trips_repaired.xml\"\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Reads logs/duarouter.log + trips.xml under base_dir.\n",
    "    2) Repairs failed trips via findAllRoutes.py in-process.\n",
    "    3) Writes out base_dir/out_trips.\n",
    "    \"\"\"\n",
    "    # Paths\n",
    "    log_path   = os.path.join(base_dir, \"logs\", \"duarouter.log\")\n",
    "    trips_path = os.path.join(base_dir, \"trips.xml\")\n",
    "\n",
    "    # 1) collect failed IDs\n",
    "    failed_ids = extract_failed_trips(log_path)\n",
    "    print(f\"Found {len(failed_ids)} failed trips.\")\n",
    "\n",
    "    # 2) parse original trips.xml\n",
    "    tree = ET.parse(trips_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # 3) map each failed trip → its fromTaz, toTaz\n",
    "    zones_for_trip = {}\n",
    "    for trip in root.findall('trip'):\n",
    "        vid = trip.get('id')\n",
    "        if vid in failed_ids:\n",
    "            zones_for_trip[vid] = (trip.get('fromTaz'), trip.get('toTaz'))\n",
    "\n",
    "    # 4) group vehicle IDs by zone‐pair\n",
    "    grouping = defaultdict(list)\n",
    "    for vid, (fz, tz) in zones_for_trip.items():\n",
    "        grouping[(fz, tz)].append(vid)\n",
    "\n",
    "    # 5) load TAZ definitions\n",
    "    taz_map = parse_taz_file(taz_file)\n",
    "\n",
    "    # 6) ensure output folder for intermediate routes\n",
    "    routes_dir = os.path.join(base_dir, out_routes_dir)\n",
    "    os.makedirs(routes_dir, exist_ok=True)\n",
    "\n",
    "    # 7) for each (fromZ, toZ), invoke findAllRoutes and cache results\n",
    "    route_cache = {}  # (fz,tz) → list of \"edge1 edge2 …\"\n",
    "    for (fz, tz), vids in grouping.items():\n",
    "        src_edges = taz_map.get(fz, [])\n",
    "        tgt_edges = taz_map.get(tz, [])\n",
    "        if not src_edges or not tgt_edges:\n",
    "            print(f\"[WARN] no edges for zone {fz} or {tz}, skipping\", file=sys.stderr)\n",
    "            continue\n",
    "\n",
    "        out_file = os.path.join(routes_dir, f\"routes_{fz}_{tz}.xml\")\n",
    "        call_findAllRoutes_inprocess(findall_script, net_file, src_edges, tgt_edges, out_file)\n",
    "\n",
    "        # parse the generated routes XML\n",
    "        routes_tree = ET.parse(out_file)\n",
    "        routes_root = routes_tree.getroot()\n",
    "        edge_lists = [r.get('edges') for r in routes_root.findall('route')]\n",
    "        if not edge_lists:\n",
    "            print(f\"[WARN] no routes found between zones {fz}->{tz}\", file=sys.stderr)\n",
    "        route_cache[(fz, tz)] = edge_lists\n",
    "\n",
    "    # 8) Replace each failed <trip> with a <vehicle route=\"…\">\n",
    "    for trip in list(root.findall('trip')):\n",
    "        vid = trip.get('id')\n",
    "        if vid not in failed_ids:\n",
    "            continue\n",
    "        fz, tz = zones_for_trip[vid]\n",
    "        candidates = route_cache.get((fz, tz))\n",
    "        if not candidates:\n",
    "            continue  # still no route, leave as-is or drop\n",
    "        chosen = candidates[0]  # pick first found route\n",
    "\n",
    "        attrib = {\n",
    "            'id':         vid,\n",
    "            'type':       trip.get('type', 'car'),\n",
    "            'depart':     trip.get('depart'),\n",
    "            'departLane': trip.get('departLane'),\n",
    "            'departPos':  trip.get('departPos'),\n",
    "            'departSpeed':trip.get('departSpeed'),\n",
    "            'route':      chosen\n",
    "        }\n",
    "        veh = ET.Element('vehicle', attrib)\n",
    "        root.append(veh)\n",
    "        root.remove(trip)\n",
    "\n",
    "    # 9) Write out the repaired trips file\n",
    "    out_path = os.path.join(base_dir, out_trips)\n",
    "    tree.write(out_path, encoding='utf-8', xml_declaration=True)\n",
    "    print(f\"Repaired trips written to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1251fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 622 failed trips.\n"
     ]
    }
   ],
   "source": [
    "repair_trips(\n",
    "    base_dir    = \"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/result/experiments/20-05-25-checknewmap\",\n",
    "    net_file    = \"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/result/net-repairment/cleaned_p2_2_newtest-osm.net.xml\",\n",
    "    taz_file    = \"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/result/experiments/20-05-25-checknewmap/taz.xml\",\n",
    "    findall_script = \"/home/hoai-linh.dao/Envs/sumo-env/lib/python3.10/site-packages/sumo/tools/findAllRoutes.py\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
