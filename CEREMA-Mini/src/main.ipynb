{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SETUP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libs && Envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import re\n",
    "from collections import OrderedDict, defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "import traci\n",
    "import sumolib\n",
    "import xml.etree.ElementTree as ET\n",
    "from pyproj import Transformer, CRS\n",
    "import networkx as nx\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import unary_union\n",
    "from shapely.errors import TopologicalError\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "# export LD_LIBRARY_PATH=~/Libs/libnsl\n",
    "# export SUMO_HOME=~/Envs/sumo-env/lib/python3.10/site-packages/sumo\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = os.path.expanduser(\"~/Libs/libnsl\")\n",
    "os.environ[\"SUMO_HOME\"] = os.path.expanduser(\"~/Envs/sumo-env/lib/python3.10/site-packages/sumo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed PATHs\n",
    "NET_XML = Path(\"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/data/newtest-osm.net.xml\")\n",
    "POLY_XML = \"/home/hoai-linh.dao/Works/EVCS/AMP-Metropole/Task-1-Completion/results/p0/newtest-poly/bassin-based.poly.xml\"\n",
    "ORIG_VTYPES_XML = \"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/data/integrated-dist.add.xml\"\n",
    "GROUPED_POLY_XML = \"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/data/group-based.poly.xml\"\n",
    "FLOW_CSV = \"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/data/flow.csv\"\n",
    "MAIN_FLOW_CSV = \"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/result/main-flow.csv\"\n",
    "\n",
    "SUMO_TOOLS_DIR = Path(\"/home/hoai-linh.dao/Envs/sumo-env/lib/python3.10/site-packages/sumo/tools\")\n",
    "REROUTING_PY = SUMO_TOOLS_DIR / \"generateContinuousRerouters.py\"\n",
    "NETCHECK_PY = SUMO_TOOLS_DIR / \"net/netcheck.py\"\n",
    "RANDOMTRIPS_PY = SUMO_TOOLS_DIR / \"randomTrips.py\"\n",
    "FINDALLROUTES_PY = SUMO_TOOLS_DIR / \"findAllRoutes.py\"\n",
    "PLOTXMLATTRIBUTES_PY = SUMO_TOOLS_DIR / \"visualization/plotXMLAttributes.py\"\n",
    "PLOTTRAJECTORIES_PY = SUMO_TOOLS_DIR / \"plot_trajectories.py\"\n",
    "PLOTNETDUMP_PY = SUMO_TOOLS_DIR / \"visualization/plot_net_dump.py\"\n",
    "PLOTNETSPEED_PY = SUMO_TOOLS_DIR / \"visualization/plot_net_speed.py\"\n",
    "PLOTNETTRAFFICLIGHTS_PY = SUMO_TOOLS_DIR / \"visualization/plot_net_trafficLights.py\"\n",
    "PLOTSUMMARY_PY = SUMO_TOOLS_DIR / \"visualization/plot_summary.py\"\n",
    "PLOTTRIPINFODISTRIBUTIONS_PY = SUMO_TOOLS_DIR / \"visualization/plot_tripinfo_distributions.py\"\n",
    "PLOTCSVTIMELINE_PY = SUMO_TOOLS_DIR / \"visualization/plot_csv_timeline.py\"\n",
    "PLOTCSVPIE_PY = SUMO_TOOLS_DIR / \"visualization/plot_csv_pie.py\"\n",
    "PLOTCSVBARS_PY = SUMO_TOOLS_DIR / \"visualization/plot_csv_bars.py\"\n",
    "MACROUTPUT_PY = SUMO_TOOLS_DIR / \"visualization/marcoOutput.py\"\n",
    "ROUTESTATS_PY = SUMO_TOOLS_DIR / \"route/routeStats.py\"\n",
    "ROUTECHECK_PY = SUMO_TOOLS_DIR / \"route/routecheck.py\"\n",
    "\n",
    "# Dynamic DIRs\n",
    "SIMULATION_DIR = Path(\"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/result/vtypes-simulation\")\n",
    "\n",
    "ODS_DIR = SIMULATION_DIR / \"ods\"\n",
    "TRIPS_DIR = SIMULATION_DIR / \"trips\"\n",
    "OUTPUTS_DIR = SIMULATION_DIR / \"outputs\"\n",
    "LOGS_DIR = SIMULATION_DIR / \"logs\"\n",
    "VISUALIZATIONS_DIR = SIMULATION_DIR / \"visualizations\"\n",
    "\n",
    "SIMULATION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "for path in [ODS_DIR, TRIPS_DIR, OUTPUTS_DIR, LOGS_DIR, VISUALIZATIONS_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dynamic PATHs\n",
    "TAZ_XML = SIMULATION_DIR / \"taz.add.xml\"\n",
    "VTYPES_DIST_XML = SIMULATION_DIR / \"vtypes-dist.add.xml\"\n",
    "ALL_TRIPS_XML = SIMULATION_DIR / \"trips.xml\"\n",
    "ROUTE_XML = SIMULATION_DIR / \"route.xml\"\n",
    "ROUTE_ALT_XML = SIMULATION_DIR / \"route.alt.xml\"\n",
    "REROUTER_XML = SIMULATION_DIR / \"rerouter.add.xml\"\n",
    "SUMOCFG_XML = SIMULATION_DIR / \"run.sumocfg\"\n",
    "\n",
    "DUAROUTER_LOG = LOGS_DIR / \"duarouter.log\"\n",
    "SIMULATION_LOG = LOGS_DIR / \"sumo_run.log\"\n",
    "REROUTING_LOG = LOGS_DIR / \"rerouting.log\"\n",
    "\n",
    "# Outputs Paths\n",
    "COLLISIONS_XML = OUTPUTS_DIR / \"collisions.xml\"\n",
    "BATTERY_XML = OUTPUTS_DIR / \"battery.xml\"\n",
    "LANECHANGES_XML = OUTPUTS_DIR / \"laneChanges.xml\"\n",
    "STATISTICS_XML = OUTPUTS_DIR / \"statistics.xml\"\n",
    "TRACE_XML = OUTPUTS_DIR / \"sumoTrace.xml\"\n",
    "SUMMARY_XML = OUTPUTS_DIR / \"summary.xml\"\n",
    "TRIPINFO_XML = OUTPUTS_DIR / \"tripinfo.xml\"\n",
    "VEHROUTES_XML = OUTPUTS_DIR / \"vehRoutes.xml\"\n",
    "NETSTATE_XML = OUTPUTS_DIR / \"netstate.xml\"\n",
    "LOG_TXT = OUTPUTS_DIR / \"log.txt\"\n",
    "\n",
    "# Visualization Paths\n",
    "PLOT_1_PNG = VISUALIZATIONS_DIR / \"plot_1.png\"\n",
    "PLOT_2_PNG = VISUALIZATIONS_DIR / \"plot_2.png\"\n",
    "\n",
    "# Net-Repairment Task\n",
    "NET_REPAIRMENT_DIR = Path(\"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/result/net-repairment\")\n",
    "CLEANED_NET_XML_1 = NET_REPAIRMENT_DIR /  f\"cleaned_1_{NET_XML.name}\"\n",
    "CLEANED_NET_XML_2 = NET_REPAIRMENT_DIR /  f\"cleaned_2_{NET_XML.name}\"\n",
    "\n",
    "KEEP_EDGES_TXT_1 = NET_REPAIRMENT_DIR / \"keep-edges_1.txt\"\n",
    "KEEP_EDGES_TXT_2 = NET_REPAIRMENT_DIR / \"keep-edges_2.txt\"\n",
    "COMPONENTS_NW_TXT_1 = NET_REPAIRMENT_DIR / \"components_nw_1.txt\"\n",
    "COMPONENTS_NW_TXT_2 = NET_REPAIRMENT_DIR / \"components_nw_2.txt\"\n",
    "\n",
    "NET_REPAIRMENT_LOGS_DIR = NET_REPAIRMENT_DIR / \"logs\"\n",
    "NETCHECK_LOG_1 = NET_REPAIRMENT_LOGS_DIR / \"netcheck_1.log\"\n",
    "NETCHECK_LOG_2 = NET_REPAIRMENT_LOGS_DIR / \"netcheck_2.log\"\n",
    "NETCHECK_LOG_3 = NET_REPAIRMENT_LOGS_DIR / \"netcheck_3.log\"\n",
    "NETCONVERT_LOG_1 = NET_REPAIRMENT_LOGS_DIR / \"netconvert_1.log\"\n",
    "NETCONVERT_LOG_2 = NET_REPAIRMENT_LOGS_DIR / \"netconvert_2.log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAZ_IDS = {\n",
    "    'marseille': '1',\n",
    "    'aix-en-provence': '2',\n",
    "    'est-etang-de-berre': '3',\n",
    "    'nord-ouest': '4',\n",
    "    'ouest-etang-de-berre': '5',\n",
    "    'sud-est': '6',\n",
    "    'hors_amp': '99'\n",
    "}\n",
    "\n",
    "BORDER_RATIO = 0.40\n",
    "REAL_ORIGIN   = 'marseille'\n",
    "\n",
    "CAR_PREFIX = \"carDist\"              \n",
    "EV_BRANDS = [\"Renault\", \"Tesla\", \"Citroen\", \"Peugeot\", \"Dacia\", \"Volkswagen\", \"BMW\", \"Fiat\", \"KIA\"]\n",
    "\n",
    "EV_RATIO = 0.20\n",
    "\n",
    "DIST_ID = \"vehDist\"\n",
    "\n",
    "# Page 11\n",
    "INCOMING_RATIO = 178729/(178729 + 174729)\n",
    "OUTGOING_RATIO = 174729/(178729 + 174729)\n",
    "INCOMING_RATIO, OUTGOING_RATIO\n",
    "\n",
    "# Page 14 + Page 15\n",
    "TRIPS_RATIO_0 = 1 # default\n",
    "TRIPS_RATIO_1 = 0.40 # Marseille \n",
    "TRIPS_RATIO_2 = 0.41 # Marseille Bassin\n",
    "TRIPS_RATIO_3 = 0.52 # AMP Bassin = CEREMA\n",
    "TRIPS_RATIO_4 = 0.10 # test\n",
    "\n",
    "PATH_REPLACEMENTS = {\n",
    "    'net-file': CLEANED_NET_XML_2,\n",
    "    'route-files': ROUTE_XML,\n",
    "    'summary-output': SUMMARY_XML,\n",
    "    'tripinfo-output': TRIPINFO_XML,\n",
    "    'fcd-output': TRACE_XML,\n",
    "    'lanechange-output': LANECHANGES_XML,\n",
    "    'battery-output': BATTERY_XML,\n",
    "    'vehroute-output': VEHROUTES_XML,\n",
    "    'collision-output': COLLISIONS_XML,\n",
    "    'netstate-dump': NETSTATE_XML,\n",
    "    'statistic-output': STATISTICS_XML,\n",
    "    'log': LOG_TXT\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PREPARATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Raw Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FLOW_CSV)\n",
    "\n",
    "columns_inter = ['Est_Etang-de-Berre','Aix-en-Provence','Sud-Est','Ouest_Etang-de-Berre','Nord-Ouest','Hors_AMP']\n",
    "df[\"Intra\"] = df[\"Total\"] - df[columns_inter].sum(axis=1)\n",
    "\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "df.to_csv(MAIN_FLOW_CSV, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repairing Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETCHECK_CMD_1 = [\n",
    "    \"python\", NETCHECK_PY,\n",
    "    NET_XML,\n",
    "    \"--vclass\", \"passenger\",\n",
    "    \"--component-output\", COMPONENTS_NW_TXT_1\n",
    "]\n",
    "\n",
    "with open(NETCHECK_LOG_1, \"w\") as f:\n",
    "    print(f\"Running NETCHECK Step 1 ...\")\n",
    "    subprocess.run(NETCHECK_CMD_1, stdout=f, stderr=subprocess.STDOUT, check=True)\n",
    "    print(f\"[DONE] Components Ouput written to {COMPONENTS_NW_TXT_1}\\n[LOG] Output logged in {NETCHECK_LOG_1}\")\n",
    "\n",
    "print()\n",
    "print(f\"Running extractMaxComponent ...\")\n",
    "extractMaxComponent(COMPONENTS_NW_TXT_1, KEEP_EDGES_TXT_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETCONVERT_CMD_1 = [\n",
    "    \"netconvert\",\n",
    "    \"--net-file\", NET_XML,\n",
    "    \"--keep-edges.input-file\", KEEP_EDGES_TXT_1,\n",
    "    \"--geometry.remove\",\n",
    "    \"--geometry.remove.min-length\", \"2\",\n",
    "    \"--geometry.max-segment-length\", \"20\",\n",
    "    \"--geometry.min-dist\", \"0.1\",\n",
    "    \"--geometry.max-angle\", \"150\",\n",
    "    \"--geometry.max-angle.fix\",\n",
    "    \"--remove-edges.isolated\",\n",
    "    \"--junctions.join\",\n",
    "    \"--junctions.join-dist\", \"60\",\n",
    "    \"--roundabouts.guess\",\n",
    "    \"--ramps.guess\",\n",
    "    \"--keep-edges.by-vclass=passenger\",\n",
    "    \"--osm.bike-access=false\",\n",
    "    \"--osm.sidewalks=false\",\n",
    "    \"--crossings.guess=false\",\n",
    "    \"--tls.guess\",\n",
    "    \"--tls.guess.threshold\", \"40\",\n",
    "    \"--tls.join\",\n",
    "    \"--tls.layout\", \"incoming\",\n",
    "    \"--tls.discard-loaded\",\n",
    "    \"--ptstop-output\", \"/dev/null\",\n",
    "    \"--ptline-output\", \"/dev/null\",\n",
    "    \"-o\", CLEANED_NET_XML_1\n",
    "]\n",
    "\n",
    "with open(NETCONVERT_LOG_1, \"w\") as f:\n",
    "    print(f\"Running NETCONVERT Step 1 ...\")\n",
    "    subprocess.run(NETCONVERT_CMD_1, stdout=f, stderr=subprocess.STDOUT, check=True)\n",
    "    print(f\"[DONE] Cleaned Network written to {CLEANED_NET_XML_1}\\n[LOG] Output logged in {NETCONVERT_LOG_1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETCHECK_CMD_2 = [\n",
    "    \"python\", NETCHECK_PY,\n",
    "    CLEANED_NET_XML_1,\n",
    "    \"--vclass\", \"passenger\",\n",
    "    \"--component-output\", COMPONENTS_NW_TXT_2,\n",
    "    \"-t\"\n",
    "]\n",
    "\n",
    "with open(NETCHECK_LOG_2, \"w\") as f:\n",
    "    print(f\"Running NETCHECK Step 2 ...\")\n",
    "    subprocess.run(NETCHECK_CMD_2, stdout=f, stderr=subprocess.STDOUT, check=True)\n",
    "    print(f\"[DONE] Output logged in {NETCHECK_LOG_2}\")\n",
    "\n",
    "print()\n",
    "print(f\"Running extractMaxComponent ...\")\n",
    "extractMaxComponent(COMPONENTS_NW_TXT_2, KEEP_EDGES_TXT_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETCONVERT_CMD_2 = [\n",
    "    \"netconvert\",\n",
    "    \"--net-file\", CLEANED_NET_XML_1,\n",
    "    \"--keep-edges.input-file\", KEEP_EDGES_TXT_2,\n",
    "    \"-o\", CLEANED_NET_XML_2\n",
    "]\n",
    "\n",
    "with open(NETCONVERT_LOG_2, \"w\") as f:\n",
    "    print(f\"Running NETCONVERT Step 2 ...\")\n",
    "    subprocess.run(NETCONVERT_CMD_2, stdout=f, stderr=subprocess.STDOUT, check=True)\n",
    "    print(f\"[DONE] Cleaned Network written to {CLEANED_NET_XML_2}\\n[LOG] Output logged in {NETCONVERT_LOG_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETCHECK_CMD_3 = [\n",
    "    \"python\", NETCHECK_PY,\n",
    "    CLEANED_NET_XML_2,\n",
    "    \"--vclass\", \"passenger\",\n",
    "    \"-t\"\n",
    "\n",
    "]\n",
    "\n",
    "with open(NETCHECK_LOG_3, \"w\") as f:\n",
    "    print(f\"Running NETCHECK Step 3 ...\")\n",
    "    subprocess.run(NETCHECK_CMD_3, stdout=f, stderr=subprocess.STDOUT, check=True)\n",
    "    print(f\"[DONE] Output logged in {NETCHECK_LOG_3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = sumolib.net.readNet(CLEANED_NET_XML_2)\n",
    "\n",
    "# Chiều A → B\n",
    "print(\"64502815#1  → 510193665:\",\n",
    "      net.getShortestPath(\n",
    "          net.getEdge('64502815#1'),\n",
    "          net.getEdge('510193665'))[0] is None)\n",
    "\n",
    "# Chiều ngược lại B → A\n",
    "print(\"510193665   → 64502815#1:\",\n",
    "      net.getShortestPath(\n",
    "          net.getEdge('510193665'),\n",
    "          net.getEdge('64502815#1'))[0] is None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUTESTATS_CMD = [\n",
    "    \"python\", ROUTESTATS_PY,\n",
    "    ROUTE_ALT_XML,\n",
    "    # \"-n\", CLEANED_NET_XML_2,\n",
    "    \"-a\", \"routeLength\",\n",
    "    \"--binwidth\", \"500\",\n",
    "    \"--hist-output\", \"/home/hoai-linh.dao/Works/EVCS/CEREMA-Mini/result/hist.dat\"\n",
    "]\n",
    "subprocess.run(ROUTESTATS_CMD, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MAIN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_tree = ET.parse(GROUPED_POLY_XML)\n",
    "poly_root = poly_tree.getroot()\n",
    "\n",
    "region_polys = defaultdict(list)\n",
    "for poly in poly_root.findall(\"poly\"):\n",
    "    region = poly.get(\"type\")\n",
    "    shape_str = poly.get(\"shape\")\n",
    "    if region and shape_str:\n",
    "        polygon = parseShape(shape_str)\n",
    "        if polygon is not None:\n",
    "            region_polys[region].append(polygon)\n",
    "\n",
    "region_geoms = {}\n",
    "for region, polys in region_polys.items():\n",
    "    if polys:\n",
    "        try:\n",
    "            region_geoms[region] = unary_union(polys)\n",
    "        except TopologicalError as e:\n",
    "            print(f\"[ERROR] Topology error in bassin {region}: {e}\")\n",
    "\n",
    "print(\"[CHECK] BBs based on bassin:\")\n",
    "for region, geom in region_geoms.items():\n",
    "    print(f\"  {region}: {geom.bounds}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = sumolib.net.readNet(CLEANED_NET_XML_2)\n",
    "tree_net = ET.parse(CLEANED_NET_XML_2)\n",
    "root_net = tree_net.getroot()\n",
    "location_elem = root_net.find(\"location\")\n",
    "if location_elem is None or \"projParameter\" not in location_elem.attrib:\n",
    "    raise ValueError(\"Not found <location> or projParameter in net.xml\")\n",
    "proj_param = location_elem.attrib[\"projParameter\"]\n",
    "target_crs = CRS.from_proj4(proj_param)\n",
    "transformer = Transformer.from_crs(\"epsg:4326\", target_crs, always_xy=True)\n",
    "\n",
    "edges_by_region = defaultdict(list)\n",
    "edges_hors = []\n",
    "\n",
    "for edge in net.getEdges():\n",
    "    if edge.getID().endswith(\"-source\") or edge.getID().endswith(\"-sink\"):\n",
    "        continue\n",
    "    shape = edge.getShape()\n",
    "    if not shape:\n",
    "        continue\n",
    "    mid_pt = shape[len(shape)//2]\n",
    "    pt = Point(mid_pt[0], mid_pt[1])\n",
    "\n",
    "    assigned = False\n",
    "    for region, geom in region_geoms.items():\n",
    "        if geom.contains(pt):\n",
    "            edges_by_region[region].append(edge)\n",
    "            assigned = True\n",
    "            break\n",
    "\n",
    "    if not assigned:\n",
    "        edges_hors.append(edge)\n",
    "        \n",
    "edges_by_region['hors_amp'] = edges_hors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = sumolib.net.readNet(CLEANED_NET_XML_2)\n",
    "\n",
    "def reachable(e_from, e_to):\n",
    "    \"\"\"True nếu có đường đi (theo passenger) từ e_from --> e_to\"\"\"\n",
    "    return net.getShortestPath(e_from, e_to)[0] is not None\n",
    "\n",
    "candidate_out  = defaultdict(list)\n",
    "candidate_in   = defaultdict(list)\n",
    "\n",
    "SAMPLE = 200\n",
    "\n",
    "for reg_from, edges_from in edges_by_region.items():\n",
    "    others = {r: es for r, es in edges_by_region.items() if r != reg_from}\n",
    "\n",
    "    for e in edges_from:\n",
    "        # --- OUT ---\n",
    "        ok_out = False\n",
    "        for reg_to, edges_to in others.items():\n",
    "            sample_to = random.sample(edges_to, min(SAMPLE, len(edges_to)))\n",
    "            if any(reachable(e, et) for et in sample_to):\n",
    "                ok_out = True\n",
    "                break\n",
    "        if ok_out:\n",
    "            candidate_out[reg_from].append(e)\n",
    "\n",
    "        # --- IN ---\n",
    "        ok_in = False\n",
    "        for reg_from2, edges_from2 in others.items():\n",
    "            sample_from2 = random.sample(edges_from2, min(SAMPLE, len(edges_from2)))\n",
    "            if any(reachable(ef2, e) for ef2 in sample_from2):\n",
    "                ok_in = True\n",
    "                break\n",
    "        if ok_in:\n",
    "            candidate_in[reg_from].append(e)\n",
    "\n",
    "root = ET.Element(\"tazs\")\n",
    "for region in edges_by_region:\n",
    "    rid = region.lower()\n",
    "    taz_id = TAZ_IDS.get(rid)\n",
    "    if not taz_id:\n",
    "        print(f\"[WARN] No TAZ id for {region}, skip\")\n",
    "        continue\n",
    "\n",
    "    geom = region_geoms.get(region)\n",
    "    cx, cy = (geom.centroid.x, geom.centroid.y) if geom else (0, 0)\n",
    "    taz = ET.SubElement(root, \"taz\", id=taz_id, x=f\"{cx:.2f}\", y=f\"{cy:.2f}\")\n",
    "\n",
    "    Nsrc = Nsink = 300\n",
    "    for e in random.sample(candidate_out[region],  min(Nsrc,  len(candidate_out[region]))):\n",
    "        ET.SubElement(taz, \"tazSource\", id=e.getID(), weight=\"1.0\")\n",
    "\n",
    "    for e in random.sample(candidate_in[region],   min(Nsink, len(candidate_in[region]))):\n",
    "        ET.SubElement(taz, \"tazSink\",   id=e.getID(), weight=\"1.0\")\n",
    "\n",
    "ET.ElementTree(root).write(TAZ_XML, encoding=\"utf-8\", xml_declaration=True)\n",
    "print(\">> TAZ written to\", TAZ_XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Direction statistics\n",
    "net = sumolib.net.readNet(CLEANED_NET_XML_2)\n",
    "internal_edges = [e for e in net.getEdges() if e.getID().startswith(':')]\n",
    "normal_edges   = [e for e in net.getEdges(True)   # chỉ edge “thường”\n",
    "                  if not e.getID().startswith(':')]\n",
    "\n",
    "print(f\"Normal edges  : {len(normal_edges):,}\")\n",
    "print(f\"Internal edges: {len(internal_edges):,}\")\n",
    "\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for e in normal_edges:\n",
    "    direction = \"one_way\"\n",
    "\n",
    "  \n",
    "    for rev in e.getToNode().getOutgoing():        \n",
    "        if rev.getToNode() is e.getFromNode():     \n",
    "            direction = \"two_way\"\n",
    "            break\n",
    "\n",
    "    counter[direction] += 1\n",
    "\n",
    "print(\"\\n--- Direction statistics ---\")\n",
    "print(f\"One-way edges : {counter['one_way']:,}\")\n",
    "print(f\"Two-way edges : {counter['two_way']:,}\")\n",
    "print(f\"Total checked : {counter['one_way'] + counter['two_way']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New proposed TAZ creation way\n",
    "BORDER_RATIO          = 0.4  \n",
    "SAMPLE_INNER          = 40  \n",
    "SAMPLE_CROSS          = 40  \n",
    "def parseShape(shape_str: str):\n",
    "    try:\n",
    "        coords = [tuple(map(float, p.split(','))) for p in shape_str.strip().split()]\n",
    "    except ValueError:\n",
    "        return None\n",
    "    if len(coords) < 3:\n",
    "        return None\n",
    "    if coords[0] != coords[-1]:\n",
    "        coords.append(coords[0])\n",
    "    poly = Polygon(coords)\n",
    "    if not poly.is_valid:\n",
    "        poly = poly.buffer(0)\n",
    "    return poly if poly.is_valid else None\n",
    "\n",
    "\n",
    "def boundary_edges(edges, geom, ratio=0.1):\n",
    "    if geom is None:\n",
    "        return []\n",
    "    minx, miny, maxx, maxy = geom.bounds\n",
    "    th = min(maxx - minx, maxy - miny) * ratio\n",
    "    boundary = geom.boundary\n",
    "    return [e for e in edges if Point(e.getShape()[len(e.getShape())//2]).distance(boundary) < th]\n",
    "\n",
    "\n",
    "def has_reverse(edge):\n",
    "    fn, tn = edge.getFromNode(), edge.getToNode()\n",
    "    return any(o.getToNode() is fn for o in tn.getOutgoing())\n",
    "\n",
    "\n",
    "def is_valid_edge(edge):\n",
    "    return (not edge.getID().startswith('-')  # skip reverse direction\n",
    "            and not edge.getID().endswith(('-source', '-sink'))\n",
    "            and edge.getShape()\n",
    "            and has_reverse(edge))            # true two‑way road\n",
    "\n",
    "\n",
    "def reachable(edge_from, edge_to, net):\n",
    "    return net.getShortestPath(edge_from, edge_to)[0] is not None\n",
    "\n",
    "\n",
    "def filter_reachable(pool, net, sample=SAMPLE_INNER):\n",
    "    \"\"\"Keep edges that can reach **and** be reached from ≥1 peer in *pool*.\"\"\"\n",
    "    if len(pool) <= 1:\n",
    "        return pool\n",
    "    keep = []\n",
    "    for e in pool:\n",
    "        targets = random.sample([x for x in pool if x is not e], min(sample, len(pool)-1))\n",
    "        ok_out = any(reachable(e, t, net) for t in targets)\n",
    "        ok_in  = any(reachable(t, e, net) for t in targets)\n",
    "        if ok_out and ok_in:\n",
    "            keep.append(e)\n",
    "    return keep\n",
    "\n",
    "# STEP‑1  Build basin geometries\n",
    "print(\"[1] Reading basins …\")\n",
    "region_geoms = defaultdict(list)\n",
    "for p in ET.parse(GROUPED_POLY_XML).getroot().findall('poly'):\n",
    "    reg = p.get('type')\n",
    "    geom = parseShape(p.get('shape', ''))\n",
    "    if reg and geom:\n",
    "        region_geoms[reg].append(geom)\n",
    "for reg, polys in region_geoms.items():\n",
    "    region_geoms[reg] = unary_union(polys) if len(polys) > 1 else polys[0]\n",
    "\n",
    "# STEP‑2  Scan network & assign edges to basins\n",
    "print(\"[2] Scanning network …\")\n",
    "NET = sumolib.net.readNet(CLEANED_NET_XML_2)\n",
    "\n",
    "edges_by_region = defaultdict(list)\n",
    "outside = []\n",
    "\n",
    "for e in NET.getEdges():\n",
    "    if not is_valid_edge(e):\n",
    "        continue\n",
    "    mid = Point(e.getShape()[len(e.getShape())//2])\n",
    "    placed = False\n",
    "    for reg, geom in region_geoms.items():\n",
    "        if geom.contains(mid):\n",
    "            edges_by_region[reg].append(e)\n",
    "            placed = True\n",
    "            break\n",
    "    if not placed:\n",
    "        outside.append(e)\n",
    "\n",
    "edges_by_region['hors_amp'] = outside\n",
    "\n",
    "# ── Inner‑basin connectivity \n",
    "print(\"[2a] Inner‑basin connectivity filter …\")\n",
    "for reg, pool in list(edges_by_region.items()):\n",
    "    kept = filter_reachable(pool, NET, SAMPLE_INNER)\n",
    "    if len(kept) < len(pool):\n",
    "        print(f\"  – {reg}: removed {len(pool)-len(kept)} isolated edges\")\n",
    "    edges_by_region[reg] = kept\n",
    "\n",
    "# ── Cross‑basin connectivity \n",
    "print(\"[2b] Cross‑basin connectivity filter …\")\n",
    "for reg_from, pool_from in list(edges_by_region.items()):\n",
    "    others = [e for r, p in edges_by_region.items() if r != reg_from for e in p]\n",
    "    if not pool_from or not others:\n",
    "        continue\n",
    "    keep = []\n",
    "    for e in pool_from:\n",
    "        tgt_sample = random.sample(others, min(SAMPLE_CROSS, len(others)))\n",
    "        ok_out = any(reachable(e, t, NET) for t in tgt_sample)\n",
    "        ok_in  = any(reachable(t, e, NET) for t in tgt_sample)\n",
    "        if ok_out and ok_in:\n",
    "            keep.append(e)\n",
    "    removed = len(pool_from) - len(keep)\n",
    "    if removed:\n",
    "        print(f\"  – {reg_from}: removed {removed} edges not reachable cross‑basin\")\n",
    "    edges_by_region[reg_from] = keep\n",
    "\n",
    "# STEP‑3  Write TAZ\n",
    "print(\"[3] Writing TAZ …\")\n",
    "root = ET.Element('tazs')\n",
    "for reg, pool in edges_by_region.items():\n",
    "    if not pool:\n",
    "        continue\n",
    "    tid = TAZ_IDS.get(reg.lower())\n",
    "    if tid is None:\n",
    "        print(f\"  ! no TAZ id for basin {reg}; skip\")\n",
    "        continue\n",
    "    geom = region_geoms.get(reg)\n",
    "    B = boundary_edges(pool, geom)\n",
    "    I = [e for e in pool if e not in B]\n",
    "    nb = int(BORDER_RATIO*len(pool))\n",
    "    ni = len(pool)-nb\n",
    "    chosen = random.sample(B, min(nb, len(B))) + random.sample(I, min(ni, len(I)))\n",
    "\n",
    "    c = geom.centroid if geom else Point(0,0)\n",
    "    taz = ET.SubElement(root, 'taz', id=str(tid), x=f\"{c.x:.2f}\", y=f\"{c.y:.2f}\")\n",
    "    for e in sorted(chosen, key=lambda x:x.getID()):\n",
    "        ET.SubElement(taz,'tazSource', id=e.getID(), weight='1.0')\n",
    "        ET.SubElement(taz,'tazSink',   id=e.getID(), weight='1.0')\n",
    "\n",
    "ET.ElementTree(root).write(TAZ_XML, encoding='utf-8', xml_declaration=True)\n",
    "print(f\"[DONE] {TAZ_XML} ready.  Run od2trips & duarouter next.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING TAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_tree = ET.parse(GROUPED_POLY_XML)\n",
    "poly_root = poly_tree.getroot()\n",
    "\n",
    "region_polys = defaultdict(list)\n",
    "for poly in poly_root.findall(\"poly\"):\n",
    "    region = poly.get(\"type\")\n",
    "    shape_str = poly.get(\"shape\")\n",
    "    if region and shape_str:\n",
    "        polygon = parseShape(shape_str)\n",
    "        if polygon is not None:\n",
    "            region_polys[region].append(polygon)\n",
    "\n",
    "region_geoms = {}\n",
    "for region, polys in region_polys.items():\n",
    "    if polys:\n",
    "        try:\n",
    "            region_geoms[region] = unary_union(polys)\n",
    "        except TopologicalError as e:\n",
    "            print(f\"[ERROR] Topology error in bassin {region}: {e}\")\n",
    "\n",
    "print(\"[CHECK] Bounding boxes (per basin):\")\n",
    "for region, geom in region_geoms.items():\n",
    "    print(f\"  {region}: {geom.bounds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = sumolib.net.readNet(CLEANED_NET_XML_2)\n",
    "\n",
    "# store edges per basin; plus list for those outside any basin (\"hors_amp\")\n",
    "edges_by_region = defaultdict(list)\n",
    "edges_hors      = []\n",
    "\n",
    "for edge in net.getEdges():\n",
    "    # skip technical source/sink edges created by netconvert\n",
    "    if edge.getID().endswith(\"-source\") or edge.getID().endswith(\"-sink\"):\n",
    "        continue\n",
    "\n",
    "    shape = edge.getShape()\n",
    "    if not shape:\n",
    "        continue\n",
    "    mid_pt = shape[len(shape) // 2]\n",
    "    pt = Point(mid_pt[0], mid_pt[1])\n",
    "\n",
    "    assigned = False\n",
    "    for region, geom in region_geoms.items():\n",
    "        if geom.contains(pt):\n",
    "            edges_by_region[region].append(edge)\n",
    "            assigned = True\n",
    "            break\n",
    "    if not assigned:\n",
    "        edges_hors.append(edge)\n",
    "\n",
    "# add \"hors_amp\" (outside) group\n",
    "edges_by_region[\"hors_amp\"] = edges_hors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_root = ET.Element(\"tazs\")\n",
    "\n",
    "for region, edges in edges_by_region.items():\n",
    "    rid    = region.lower()\n",
    "    taz_id = TAZ_IDS.get(rid)\n",
    "    if not taz_id:\n",
    "        print(f\"[ERROR] No TAZ ID for {region}, skip\")\n",
    "        continue\n",
    "\n",
    "    geom = region_geoms.get(region)\n",
    "    if geom is None:\n",
    "        B, I = [], edges[:]\n",
    "    else:\n",
    "        B = selectBoundaryEdges(edges, geom, threshold_ratio=0.1)\n",
    "        I = [e for e in edges if e not in B]\n",
    "\n",
    "    if region == \"hors_amp\":\n",
    "        conns = edges[:]\n",
    "    else:\n",
    "        total = len(B) + len(I)\n",
    "        nB    = int(BORDER_RATIO * total)\n",
    "        nI    = total - nB\n",
    "        conns = random.sample(B, min(nB, len(B))) + \\\n",
    "                random.sample(I, min(nI, len(I)))\n",
    "\n",
    "    print(f\"[CHECK] Basin {region}: total={len(edges)} | B={len(B)} | I={len(I)} | selected={len(conns)}\")\n",
    "\n",
    "    cent = geom.centroid if geom is not None else Point(0, 0)\n",
    "    taz  = ET.SubElement(taz_root, \"taz\", id=str(taz_id), x=f\"{cent.x:.2f}\", y=f\"{cent.y:.2f}\")\n",
    "    for e in sorted(conns, key=lambda _e: _e.getID()):\n",
    "        ET.SubElement(taz, \"tazSource\", id=e.getID(), weight=\"1.0\")\n",
    "        ET.SubElement(taz, \"tazSink\",   id=e.getID(), weight=\"1.0\")\n",
    "\n",
    "ET.ElementTree(taz_root).write(TAZ_XML, encoding=\"utf-8\", xml_declaration=True)\n",
    "print(f\"\\n[DONE] TAZ file written to {TAZ_XML}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Ods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_files = generateOds(\n",
    "    MAIN_FLOW_CSV,\n",
    "    ODS_DIR,\n",
    "    TAZ_IDS,\n",
    "    real_origin=\"marseille\",\n",
    "    exclude_cols={\"total\",\"intra\"},\n",
    "    trips_ratio=TRIPS_RATIO_4,\n",
    "    scale_in=INCOMING_RATIO,\n",
    "    scale_out=OUTGOING_RATIO\n",
    ")\n",
    "\n",
    "\n",
    "for hour, path in matrix_files:\n",
    "    size = os.path.getsize(path)\n",
    "    print(f\"[DONE] OD matrix hour {hour}: {path} ({size} bytes)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Vtypes Distribution (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignProbabilitiesToVtypes(\n",
    "    vtypes_xml=ORIG_VTYPES_XML,\n",
    "    dist_id=\"vehDist\",\n",
    "    ev_brands=EV_BRANDS,\n",
    "    ev_ratio=0.2,\n",
    "    output_xml=VTYPES_DIST_XML\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Trips from Ods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Call od2trips for all ...\")\n",
    "trips_files = od2tripsForAll(TAZ_XML, TRIPS_DIR, ODS_DIR, DIST_ID)\n",
    "print()\n",
    "print(\"[DONE] Finished 24 Trips based on hours.\")\n",
    "\n",
    "mergeTrips(TRIPS_DIR, ALL_TRIPS_XML)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUAROUTER_ADDS = \",\".join([str(VTYPES_DIST_XML), str(TAZ_XML)])\n",
    "DUAROUTER_CMD = [\n",
    "    \"duarouter\",\n",
    "    \"-n\", CLEANED_NET_XML_2,            \n",
    "    \"-r\", ALL_TRIPS_XML,            \n",
    "    # \"-a\", DUAROUTER_ADDS,\n",
    "    \"-a\", VTYPES_DIST_XML,\n",
    "    # \"--keep-vtype-distributions\",\n",
    "    # \"--with-taz\",\n",
    "    # \"--repair\",                      \n",
    "    # \"--remove-loops\",               \n",
    "    \"--randomize-flows\",         \n",
    "    \"-o\", ROUTE_XML,    \n",
    "    \"--log\", DUAROUTER_LOG,\n",
    "    \"--exit-times\",\n",
    "    \"--named-routes\",\n",
    "    \"--route-length\",\n",
    "    \"--write-costs\"\n",
    "]\n",
    "\n",
    "print(\"Running DUAROUTER Step ...\")\n",
    "subprocess.run(DUAROUTER_CMD, check=True)\n",
    "print(f\"[DONE] Routes written in {ROUTE_XML}\\n[LOG] Output logged in {DUAROUTER_LOG}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating ReRouter (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REROUTING_CMD = [\n",
    "    \"python\", REROUTING_PY,\n",
    "    \"-n\", CLEANED_NET_XML_2,\n",
    "    \"-o\", REROUTER_XML,\n",
    "    \"--vclass\", \"passenger\",\n",
    "]\n",
    "\n",
    "with open(REROUTING_LOG, \"w\") as f:\n",
    "    print(\"Running REROUTING Step ...\")\n",
    "    subprocess.run(REROUTING_CMD, stdout=f, stderr=subprocess.STDOUT, check=True)\n",
    "    print(f\"[DONE] Rerouter file is created in {REROUTER_XML}\\n[LOG] Output logged in {REROUTING_LOG}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating SUMOCFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updateSumoCfg(\n",
    "    cfg_path=SUMOCFG_XML,\n",
    "    output_path=SUMOCFG_XML,\n",
    "    replacements=PATH_REPLACEMENTS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATION_CMD = [\n",
    "    \"sumo\",             \n",
    "    \"-c\", SUMOCFG_XML,\n",
    "    \"--no-step-log\",      \n",
    "    \"--duration-log.statistics\",\n",
    "    \"--xml-validation\", \"never\"  \n",
    "]\n",
    "\n",
    "with open(SIMULATION_LOG, \"w\") as f:\n",
    "    print(\"Running SUMO simulation ...\")\n",
    "    subprocess.run(SIMULATION_CMD, stdout=f, stderr=subprocess.STDOUT, check=True)\n",
    "    print(f\"[DONE] Simulation outputs are created in {SIMULATION_DIR}\\n[LOG] Output logged in {SIMULATION_LOG}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **VISUALIZATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_CMD_1 = [\n",
    "    \"python\", PLOTXMLATTRIBUTES_PY,\n",
    "    VEHROUTES_XML,                 \n",
    "    \"-x\", \"depart\",      \n",
    "    \"-y\", \"arrival\",             \n",
    "    \"-o\", PLOT_1_PNG,\n",
    "    \"--scatterplot\"\n",
    "]\n",
    "\n",
    "subprocess.run(PLOT_CMD_1, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_CMD_2 = [\n",
    "    \"python\", PLOTXMLATTRIBUTES_PY,\n",
    "    TRACE_XML,                 \n",
    "    \"-x\", \"x\",     \n",
    "    \"-y\", \"y\",             \n",
    "    \"-o\", PLOT_2_PNG,\n",
    "    \"--scatterplot\"\n",
    "]\n",
    "\n",
    "subprocess.run(PLOT_CMD_2, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! od2trips --help"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
